{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c42f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://localhost:11434/v1\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"local-testt-key-123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301387be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"classification\": \"Tech Profile\",\n",
      "  \"confidence\": \"High\",\n",
      "  \"reasons\": [\n",
      "    \"John's professional background is primarily in software engineering, which involves designing, developing, and maintaining applications that are crucial components of the tech industry.\",\n",
      "    \"His expertise includes working on backend systems using technologies like Python, Django, and Flask, indicating a strong foundation in software development, which falls under the Tech profile criteria.\",\n",
      "    \"Experience with cloud platforms such as AWS and Docker, along with mentoring junior developers, suggests he has practical experience in IT infrastructure management and knowledge sharing, further supporting the classification of this profile as a Tech Profile.\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "\n",
    "client = OpenAI( base_url = os.environ[\"OPENAI_API_BASE\"], api_key = os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Mock RAG retrieved content (can come from vector DB)\n",
    "user_profile = \"\"\"\n",
    "John has 6 years of experience as a software engineer.\n",
    "He has worked on backend systems using Python, Django, and Flask.\n",
    "He has experience with cloud platforms like AWS and Docker.\n",
    "He occasionally mentors junior developers.\n",
    "\"\"\"\n",
    "\n",
    "# User question\n",
    "user_question = \"Is this a Tech profile?\"\n",
    "\n",
    "# ---------------------------\n",
    "# WELL-STRUCTURED PROMPT\n",
    "# ---------------------------\n",
    "prompt = f\"\"\"\n",
    "You are an AI system that analyzes user profiles.\n",
    "\n",
    "TASK:\n",
    "Determine whether the given user profile represents a TECH profile.\n",
    "\n",
    "DEFINITION:\n",
    "A Tech profile typically includes experience in:\n",
    "- Software development\n",
    "- Data, AI, or ML\n",
    "- IT infrastructure or cloud\n",
    "- Engineering or technical problem solving\n",
    "\n",
    "USER QUESTION:\n",
    "{user_question}\n",
    "\n",
    "USER PROFILE:\n",
    "{user_profile}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Classify the profile as one of:\n",
    "   - \"Tech Profile\"\n",
    "   - \"Non-Tech Profile\"\n",
    "   - \"Mixed Profile\"\n",
    "\n",
    "2. Provide 2â€“3 clear reasons for your classification.\n",
    "\n",
    "3. Respond strictly in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"classification\": \"<Tech Profile / Non-Tech Profile / Mixed Profile>\",\n",
    "  \"confidence\": \"<High / Medium / Low>\",\n",
    "  \"reasons\": [\n",
    "    \"Reason 1\",\n",
    "    \"Reason 2\",\n",
    "    \"Reason 3\"\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# Invoke LLM\n",
    "response = client.responses.create(\n",
    "    model=\"glm4:latest\",\n",
    "    input=prompt,\n",
    "    max_output_tokens=300\n",
    ")\n",
    "\n",
    "# Output\n",
    "print(response.output_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
